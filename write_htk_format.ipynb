{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import mmsdk package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import SDK_PATH, DATA_PATH, WORD_EMB_PATH, CACHE_PATH\n",
    "import sys\n",
    "\n",
    "if SDK_PATH is None:\n",
    "    print(\"SDK path is not specified! Please specify first in constants/paths.py\")\n",
    "    exit(0)\n",
    "else:\n",
    "    sys.path.append(SDK_PATH)\n",
    "\n",
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "# create folders for storing the data\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    check_call(' '.join(['mkdir', '-p', DATA_PATH]), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 3227\n",
      "train 2249\n",
      "valid 300\n",
      "test 678\n"
     ]
    }
   ],
   "source": [
    "DATASET = md.cmu_mosei\n",
    "all_num = DATASET.standard_folds.standard_train_fold + \\\n",
    "     DATASET.standard_folds.standard_test_fold + \\\n",
    "     DATASET.standard_folds.standard_valid_fold\n",
    "print('all', len(all_num))\n",
    "print('train', len(DATASET.standard_folds.standard_train_fold))\n",
    "print('valid', len(DATASET.standard_folds.standard_valid_fold))\n",
    "print('test', len(DATASET.standard_folds.standard_test_fold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation import to modify mmsdk dataset alignment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmsdk.mmdatasdk import log, computational_sequence\n",
    "import numpy\n",
    "import time\n",
    "import struct\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheritate from mmsdk with new methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_htk_format(features, feature_type, folder, video_number):\n",
    "    '''\n",
    "    This function works for function align_upsampling_and_save. It save feature vectors of one video id into one \n",
    "    htk format file. \n",
    "    feature: feature of one video\n",
    "    All files are of USER type.\n",
    "    number of samples being consistent with number of samples in csd file\n",
    "    sample bytes for COVAREP: 4 * 74 = 296\n",
    "    sample period: 10 000.0 us (100000)\n",
    "    paramkind: USER (9)\n",
    "    '''\n",
    "    #set default extension\n",
    "    ext = '.txt'\n",
    "    file_name = os.path.join(folder, feature_type, video_number)\n",
    "\n",
    "    num_sample = len(features)\n",
    "    byte_n_sample = num_sample.to_bytes(4, byteorder='big')\n",
    "\n",
    "    period = 100000\n",
    "    byte_period = period.to_bytes(4, byteorder = 'big')\n",
    "\n",
    "    if feature_type == 'COVAREP':\n",
    "        sample_b = 296\n",
    "        ext = '.cov'\n",
    "    elif feature_type == 'WordVec':\n",
    "        sample_b = 1200\n",
    "        ext = '.wvec'\n",
    "\n",
    "    byte_sample_b = sample_b.to_bytes(2, byteorder = 'big')\n",
    "\n",
    "    sample_type = 9\n",
    "    byte_sample_type = sample_type.to_bytes(2, byteorder = 'big')\n",
    "    header = byte_n_sample + byte_period + byte_sample_b + byte_sample_type\n",
    "\n",
    "    output_byte = b''\n",
    "    '''\n",
    "    try:\n",
    "        print(type(features))\n",
    "        print(type(features[0]))\n",
    "    except:\n",
    "        print('features cannot be indexed')\n",
    "        \n",
    "    try:\n",
    "        print(features[0].shape)\n",
    "    except:\n",
    "        print('features[0] is not np array')\n",
    "    '''\n",
    "    for datapoint in features:\n",
    "        y = list(map(lambda x: struct.pack('>f', x), datapoint))\n",
    "        byte_datapoint = b''.join(y)\n",
    "\n",
    "        output_byte += byte_datapoint\n",
    "\n",
    "    with open(file_name + ext, 'wb') as file:\n",
    "        file.write(header + output_byte)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle, os, json, codecs\n",
    "\n",
    "\n",
    "def save_intervals(intervals, feature_type, folder, video_number):\n",
    "    #set default extension\n",
    "    ext = '.json'\n",
    "    video_number = 'intervals_' + video_number\n",
    "    file_name = os.path.join(folder, feature_type, video_number)\n",
    "    \n",
    "    if type(intervals) != list:\n",
    "        intervals = intervals.tolist()\n",
    "    json.dump(intervals, codecs.open(file_name + ext, 'w', encoding='utf-8'), indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_mmdataset(md.mmdataset):\n",
    "    #TODO: Need tqdm bar for this as well\n",
    "    def get_relevant_entries(self,reference):\n",
    "        relevant_entries={}\n",
    "        relevant_entries_np={}\n",
    "\n",
    "        #pbar = tqdm(total=count,unit=\" Computational Sequence Entries\",leave=False)\n",
    "\n",
    "        #otherseq_key: OpenFace, wordvec, etc\n",
    "        for otherseq_key in set(list(self.computational_sequences.keys()))-set([reference]):\n",
    "            relevant_entries[otherseq_key]={}\n",
    "            relevant_entries_np[otherseq_key]={}\n",
    "            sub_compseq=self.computational_sequences[otherseq_key]\n",
    "            # for some_id in all video ids\n",
    "            for key in list(sub_compseq.data.keys()):\n",
    "                keystripped=key.split('[')[0]\n",
    "                if keystripped not in relevant_entries[otherseq_key]:                           \n",
    "                    relevant_entries[otherseq_key][keystripped]={}\n",
    "                    relevant_entries[otherseq_key][keystripped][\"intervals\"]=[]                     \n",
    "                    relevant_entries[otherseq_key][keystripped][\"features\"]=[]                                                            \n",
    "                    \n",
    "                relev_intervals=self.computational_sequences[otherseq_key].data[key][\"intervals\"]                                             \n",
    "                relev_features=self.computational_sequences[otherseq_key].data[key][\"features\"]         \n",
    "                if len(relev_intervals.shape)<2:\n",
    "                    relev_intervals=relev_intervals[None,:]\n",
    "                    relev_features=relev_features[None,:]\n",
    "\n",
    "                relevant_entries[otherseq_key][keystripped][\"intervals\"].append(relev_intervals)\n",
    "                relevant_entries[otherseq_key][keystripped][\"features\"].append(relev_features)\n",
    "                \n",
    "            for key in list(relevant_entries[otherseq_key].keys()):\n",
    "                relev_intervals_np=numpy.concatenate(relevant_entries[otherseq_key][key][\"intervals\"],axis=0)                                 \n",
    "                relev_features_np=numpy.concatenate(relevant_entries[otherseq_key][key][\"features\"],axis=0)\n",
    "                sorted_indices=sorted(range(relev_intervals_np.shape[0]),key=lambda x: relev_intervals_np[x,0])                               \n",
    "                relev_intervals_np=relev_intervals_np[sorted_indices,:]                         \n",
    "                relev_features_np=relev_features_np[sorted_indices,:]\n",
    "\n",
    "                relevant_entries_np[otherseq_key][key]={}\n",
    "                relevant_entries_np[otherseq_key][key][\"intervals\"]=relev_intervals_np\n",
    "                relevant_entries_np[otherseq_key][key][\"features\"]=relev_features_np\n",
    "            log.status(\"Pre-alignment done for <%s> ...\"%otherseq_key)\n",
    "        return relevant_entries_np\n",
    "    \n",
    "    def intersect_and_copy_upsampling(self, ref_all, relevant_entry, not_enough_label, epsilon, log_file, feature_info):\n",
    "        #ref_all: reference_entries[other_key][entry_key]['intervals'] e.g. [COVAREP][some video id]['intervals']\n",
    "        #relevant_entry: relevant_entries[other_key][entry_key] e.g. [COVAREP][some video id]\n",
    "        #epsilon: error allowed in alignment\n",
    "        #ref_time < one interval in relevant_entry\n",
    "        \n",
    "        pbar_small=log.progress_bar(total=ref_all.shape[0],unit=\" Segments\",leave=False)\n",
    "        pbar_small.set_description(\"Aligning: \" + feature_info)\n",
    "        \n",
    "        sub=relevant_entry[\"intervals\"]\n",
    "        features=relevant_entry[\"features\"]\n",
    "        \n",
    "        #finding where intersect happens\n",
    "        pointer_b = 0 # for relevant_entry\n",
    "        aligned_sub = []\n",
    "        aligned_feature = []\n",
    "        \n",
    "        for i, inter in enumerate(ref_all):\n",
    "            #print(pointer_b)\n",
    "            if (abs(inter[0]-inter[1])<epsilon):\n",
    "                pbar_small.update(1)\n",
    "                continue\n",
    "            pointer_c = pointer_b\n",
    "            while(pointer_c < sub.shape[0]):\n",
    "                if (inter[0] - sub[pointer_c][0]) > (-epsilon) and (sub[pointer_c][1] - inter[0]) > (-epsilon):\n",
    "                    aligned_sub.append(sub[pointer_c])\n",
    "                    aligned_feature.append(features[pointer_c])\n",
    "                    break\n",
    "                else:\n",
    "                    pointer_c += 1\n",
    "                \n",
    "            if pointer_c == sub.shape[0]:\n",
    "                diff = list(map(lambda x: abs(inter[0] - x), sub[:, 0]))\n",
    "                min_diff = min(diff)\n",
    "                pointer_c = diff.index(min_diff)\n",
    "                with open(log_file, 'w+') as fi:\n",
    "                    fi.write('no corresponding frame, find the closest one, {}, difference: {}\\n'.format(feature_info, min_diff))\n",
    "                aligned_sub.append(sub[pointer_c])\n",
    "                aligned_feature.append(features[pointer_c])\n",
    "            else:\n",
    "                pointer_b = pointer_c\n",
    "\n",
    "            pbar_small.update(1)\n",
    "        \n",
    "        aligned_sub = np.array(aligned_sub)\n",
    "        aligned_feature = np.array(aligned_feature)\n",
    "        zero_idx = np.where(np.isinf(aligned_feature))\n",
    "        aligned_feature[zero_idx] = 0\n",
    "\n",
    "        pbar_small.close()\n",
    "        return aligned_sub,aligned_feature\n",
    "    \n",
    "    def align_upsampling_and_save(self, reference, id_idx, label_dataset, collapse_function=None, epsilon = 10e-6):\n",
    "        folder = '/data/mifs_scratch/yw454/cmumosei_aligned'\n",
    "        log_file = './mosei_alignment_log.txt'\n",
    "        not_enough_label_file = './mosei_notenough_lable_videos.txt'\n",
    "        no_valid_label_file = './mosei_no_lable_videos.txt'\n",
    "        \n",
    "        #aligned_output = {}\n",
    "        count = 0\n",
    "        \n",
    "        ##self.computational_sequences.keys are COVERAP, OpenFace, WordVec, etc\n",
    "        #for sequence_name in self.computational_sequences.keys():\n",
    "        #    #init a dictionary to store different featues seperately\n",
    "        #    aligned_output[sequence_name]={}\n",
    "        \n",
    "        if reference not in self.computational_sequences.keys():\n",
    "            log.error(\"Computational sequence <%s> does not exist in dataset\"%reference,error=True)\n",
    "        \n",
    "        #get data of reference feature\n",
    "        refseq=self.computational_sequences[reference].data\n",
    "        #unifying the dataset, removing any entries that are not in the reference computational sequence\n",
    "        self.unify()\n",
    "        \n",
    "        #building the relevant entries to the reference - what we do in this section is simply removing all the [] from the entry ids and populating them into a new dictionary\n",
    "        log.status(\"Pre-alignment based on <%s> computational sequence started ...\"%reference)\n",
    "        \n",
    "        relevant_entries=self.get_relevant_entries(reference)\n",
    "        log.status(\"Alignment starting ...\")\n",
    "        \n",
    "        \n",
    "        pbar = log.progress_bar(total=len(refseq.keys()),unit=\" Computational Sequence Entries\",leave=False)\n",
    "        pbar.set_description(\"Overall Progress\")\n",
    "        # for some_id in all video ids\n",
    "        for entry_key in list(refseq.keys()):\n",
    "            not_enough_label = False\n",
    "            if entry_key in id_idx:\n",
    "                stored_idx = id_idx.index(entry_key)\n",
    "                if stored_idx < 104 or (stored_idx > 104 and stored_idx < 1781):\n",
    "                #if stored_idx != 1781:\n",
    "                    continue\n",
    "            \n",
    "            label_len = label_dataset[entry_key]['intervals'][-1][1] - label_dataset[entry_key]['intervals'][0][0]\n",
    "            reference_len = refseq[entry_key]['intervals'][-1][1] - refseq[entry_key]['intervals'][0][0]\n",
    "            div = reference_len / label_len\n",
    "            if div > 2:\n",
    "                not_enough_label = True\n",
    "                with open(not_enough_label_file, 'w+') as fw:\n",
    "                    fw.write(entry_key + '\\n')\n",
    "            if label_len < 0:\n",
    "                with open(no_valid_label_file, 'w+') as fw:\n",
    "                    fw.write(entry_key + '\\n')\n",
    "                \n",
    "            all_intersects = {}\n",
    "            all_intersect_features = {}\n",
    "            \n",
    "            #for sequence_name in self.computational_sequences.keys():\n",
    "            #    all_intersects[sequence_name] = []\n",
    "            #    all_intersect_features[sequence_name] = []\n",
    "            \n",
    "            ref_all=refseq[entry_key]['intervals']\n",
    "                \n",
    "            #aligning all sequences to ref sequence (previous: align refer to refer as well, now: not include refer)\n",
    "            #otherseq_key: other features; entry_key: some video id\n",
    "                \n",
    "            for otherseq_key in list(self.computational_sequences.keys()):\n",
    "                if otherseq_key != reference:\n",
    "                    feature_info = 'reference: {}, other feature {}, video id: {}'.format(reference, otherseq_key, entry_key)\n",
    "                    intersects,intersects_features=self.intersect_and_copy_upsampling(ref_all,relevant_entries[otherseq_key][entry_key], not_enough_label, epsilon, log_file, feature_info)\n",
    "                else:\n",
    "                    intersects,intersects_features=refseq[entry_key]['intervals'][:,:],refseq[entry_key]['features'][:,:]\n",
    "                    \n",
    "                #print(type(intersects[0]))\n",
    "                #print(type(intersects_features[0]))\n",
    "                #print(len(intersects[0]))\n",
    "                #print(len(intersects_features[0]))\n",
    "                all_intersects[otherseq_key] = intersects\n",
    "                all_intersect_features[otherseq_key] = intersects_features\n",
    "                    \n",
    "\n",
    "            #save features per video\n",
    "            for sequence_name in self.computational_sequences.keys():\n",
    "                video_code = id_idx.index(entry_key)\n",
    "                video_code = str(video_code).zfill(6)\n",
    "                \n",
    "                save_htk_format(all_intersect_features[sequence_name], sequence_name, folder, video_code)\n",
    "                save_intervals(all_intersects[sequence_name], sequence_name, folder, video_code)\n",
    "                print('alignment saved for video {} feature {}.'.format(video_code, sequence_name))\n",
    "            \n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your different modalities - refer to the filenames of the CSD files\n",
    "basic_dict={'COVAREP': DATA_PATH + 'CMU_MOSEI_COVAREP.csd', \n",
    "            'WordVec': DATA_PATH + 'CMU_MOSEI_TimestampedWordVectors.csd'}\n",
    "second_dict = {'Facet': DATA_PATH + 'CMU_MOSEI_VisualFacet42.csd',\n",
    "            'OpenFace': DATA_PATH + 'CMU_MOSEI_VisualOpenFace2.csd'}\n",
    "other_dict = {'Word': DATA_PATH + 'CMU_MOSEI_TimestampedWords.csd',\n",
    "             'Phone': DATA_PATH + 'CMU_MOSEI_TimestampedPhones.csd'}\n",
    "label_dict = {'mylabels':DATA_PATH + 'CMU_MOSEI_Labels.csd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU_MOSEI_VisualOpenFace2.csd\n",
      "CMU_MOSEI_TimestampedWords.csd\n",
      "CMU_MOSEI_COVAREP.csd\n",
      "CMU_MOSEI_VisualFacet42.csd\n",
      "CMU_MOSEI_TimestampedWordVectors.csd\n",
      "CMU_MOSEI_TimestampedPhones.csd\n",
      "CMU_MOSEI_Labels.csd\n",
      "COVAREP.zip\n"
     ]
    }
   ],
   "source": [
    "# list the directory contents... let's see what features there are\n",
    "data_files = os.listdir(DATA_PATH)\n",
    "print('\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validators eliminated\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:19.612] | Success | \u001b[0mComputational sequence read from file /data/mifs_scratch/yw454/cmu_mosei_latest/CMU_MOSEI_COVAREP.csd ...\n",
      "\u001b[93m\u001b[1m[2021-01-29 16:06:20.447] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "validators eliminated\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:20.449] | Success | \u001b[0mComputational sequence read from file /data/mifs_scratch/yw454/cmu_mosei_latest/CMU_MOSEI_TimestampedWordVectors.csd ...\n",
      "\u001b[93m\u001b[1m[2021-01-29 16:06:20.689] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:20.690] | Success | \u001b[0mDataset initialized successfully ... \n",
      "validators eliminated\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:20.692] | Success | \u001b[0mComputational sequence read from file /data/mifs_scratch/yw454/cmu_mosei_latest/CMU_MOSEI_VisualFacet42.csd ...\n",
      "\u001b[93m\u001b[1m[2021-01-29 16:06:20.920] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "validators eliminated\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:20.922] | Success | \u001b[0mComputational sequence read from file /data/mifs_scratch/yw454/cmu_mosei_latest/CMU_MOSEI_VisualOpenFace2.csd ...\n",
      "\u001b[93m\u001b[1m[2021-01-29 16:06:21.148] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:21.149] | Success | \u001b[0mDataset initialized successfully ... \n",
      "validators eliminated\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:21.151] | Success | \u001b[0mComputational sequence read from file /data/mifs_scratch/yw454/cmu_mosei_latest/CMU_MOSEI_Labels.csd ...\n",
      "\u001b[93m\u001b[1m[2021-01-29 16:06:21.340] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-01-29 16:06:21.340] | Success | \u001b[0mDataset initialized successfully ... \n"
     ]
    }
   ],
   "source": [
    "basic_dataset = new_mmdataset(basic_dict)\n",
    "second_dataset = new_mmdataset(second_dict)\n",
    "label_dataset = new_mmdataset(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "[COVAREP, WordVec] = [basic_dataset.computational_sequences['COVAREP'],\n",
    "                        basic_dataset.computational_sequences['WordVec']]\n",
    "label = label_dataset.computational_sequences['mylabels']\n",
    "OpenFace = second_dataset.computational_sequences['OpenFace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82.753 100.555]\n",
      " [119.919 125.299]\n",
      " [  4.84   14.052]\n",
      " [ 13.211  27.521]\n",
      " [ 26.541  41.3  ]\n",
      " [ 74.083  82.776]]\n"
     ]
    }
   ],
   "source": [
    "some_id = list(label.keys())[1]\n",
    "if some_id in all_num:\n",
    "    print(label[some_id]['intervals'][:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03206996277692446\n"
     ]
    }
   ],
   "source": [
    "utterance = 0\n",
    "yesterday = 0\n",
    "for i, video in enumerate(list(WordVec.keys())):\n",
    "    utterance += WordVec[video]['intervals'].shape[0]\n",
    "    if i > 2132 and i <= 2270: # and i >= 780: \n",
    "        yesterday += WordVec[video]['intervals'].shape[0]\n",
    "            \n",
    "print(yesterday / utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nweird_acoustic = []\\nnorm_acoustic = []\\nfor i, k in enumerate(list(COVAREP.keys())):\\n    interval = COVAREP[k]['intervals']\\n    end_frame = int((interval[-1][0] - interval[0][0]) * 100)\\n    if abs(end_frame - (len(interval) - 1)) > 3:\\n        weird_acoustic.append(k)\\n        #print(end_frame, (len(interval) - 1))\\n    else:\\n        norm_acoustic.append(k)\\n    if i == 0:\\n        print(interval[:, :])\\n        \\n      \\nprint(len(weird_acoustic))\\n#print(len(norm_acoustic))\\nif len(weird_acoustic) > 2:\\n    for i in range(2):\\n        interval = COVAREP[weird_acoustic[i]]['intervals'][:, :]\\n\\n        for j in range(len(interval) - 1):\\n\\n            if abs(interval[j][1] - interval[j+1][0]) > 1e-6:\\n                print(j, interval[j][1], interval[j+1][0])\\n            \\n\\n            if abs(interval[j][1] - interval[j][0] - 0.01) >  1e-6:\\n                print(j, interval[j][1], interval[j][0])\\n            \\n\\n        print(COVAREP[weird_acoustic[i]]['intervals'][-1])\\n        print(COVAREP[weird_acoustic[i]]['intervals'][0])\\n\\n        print(int((interval[-1][0] - interval[0][0]) * 100))\\n        print(len(COVAREP[weird_acoustic[i]]['intervals']) - 1)\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "weird_acoustic = []\n",
    "norm_acoustic = []\n",
    "for i, k in enumerate(list(COVAREP.keys())):\n",
    "    interval = COVAREP[k]['intervals']\n",
    "    end_frame = int((interval[-1][0] - interval[0][0]) * 100)\n",
    "    if abs(end_frame - (len(interval) - 1)) > 3:\n",
    "        weird_acoustic.append(k)\n",
    "        #print(end_frame, (len(interval) - 1))\n",
    "    else:\n",
    "        norm_acoustic.append(k)\n",
    "    if i == 0:\n",
    "        print(interval[:, :])\n",
    "        \n",
    "      \n",
    "print(len(weird_acoustic))\n",
    "#print(len(norm_acoustic))\n",
    "if len(weird_acoustic) > 2:\n",
    "    for i in range(2):\n",
    "        interval = COVAREP[weird_acoustic[i]]['intervals'][:, :]\n",
    "\n",
    "        for j in range(len(interval) - 1):\n",
    "\n",
    "            if abs(interval[j][1] - interval[j+1][0]) > 1e-6:\n",
    "                print(j, interval[j][1], interval[j+1][0])\n",
    "            \n",
    "\n",
    "            if abs(interval[j][1] - interval[j][0] - 0.01) >  1e-6:\n",
    "                print(j, interval[j][1], interval[j][0])\n",
    "            \n",
    "\n",
    "        print(COVAREP[weird_acoustic[i]]['intervals'][-1])\n",
    "        print(COVAREP[weird_acoustic[i]]['intervals'][0])\n",
    "\n",
    "        print(int((interval[-1][0] - interval[0][0]) * 100))\n",
    "        print(len(COVAREP[weird_acoustic[i]]['intervals']) - 1)\n",
    "\n",
    "'''    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "wordvec_with_gap = {}\n",
    "not_zeros_start = set()\n",
    "#video = list(WordVec.keys())[0]\n",
    "for k in list(WordVec.keys()):\n",
    "    interval = WordVec[k]['intervals']\n",
    "    #if k == video:\n",
    "    #    print(interval[:, :])\n",
    "    if int(np.floor(interval[0][0])) != 0:\n",
    "        not_zeros_start.add(k)\n",
    "        print(interval[0][0])\n",
    "    for i in range(interval.shape[0] - 1):\n",
    "        #if k == video:\n",
    "        #    print(interval[i+1][0], interval[i][1])\n",
    "        if abs(interval[i + 1][0] - interval[i][1]) > 1e-3:\n",
    "            if k in wordvec_with_gap:\n",
    "                wordvec_with_gap[k] += 1\n",
    "            else:\n",
    "                wordvec_with_gap[k] = 1\n",
    "\n",
    "print(wordvec_with_gap)\n",
    "print(len(not_zeros_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZDz8Qr-sJ3E\n",
      "COVAREP last interval 119.35000000000001\n",
      "WordVec last interval 119.321315193\n",
      "73.217\n",
      "[[80.728 90.987]\n",
      " [14.159 23.041]\n",
      " [22.041 26.483]\n",
      " [67.638 73.217]]\n",
      "trQLgl6ncmk\n",
      "COVAREP last interval 98.17\n",
      "WordVec last interval 98.1394558821\n",
      "59.818\n",
      "[[74.881 80.66 ]\n",
      " [79.66  96.564]\n",
      " [13.98  20.128]\n",
      " [31.25  44.912]\n",
      " [53.709 59.818]]\n"
     ]
    }
   ],
   "source": [
    "not_enough_word = set()\n",
    "not_enough_label = set()\n",
    "error_video = set()\n",
    "no_labels = set()\n",
    "label_keys = set(label.keys())\n",
    "long_video_file = './video_short_label.txt'\n",
    "\n",
    "for k in list(COVAREP.keys()):\n",
    "    acoustic = COVAREP[k]['intervals'][-1][1]\n",
    "    language = WordVec[k]['intervals'][-1][1]\n",
    "    \n",
    "    if language / acoustic > 2 or acoustic / language > 2 or language / acoustic < 0:\n",
    "        not_enough_word.add(k)\n",
    "    \n",
    "    if k in label_keys:\n",
    "        annotations = label[k]['intervals'][-1][1] - label[k]['intervals'][0][0]\n",
    "        \n",
    "        if annotations < 0: # annotations / acoustic > 2 or acoustic / annotations > 2 or \n",
    "        #if annotations - language > 1:\n",
    "            if k in all_num:\n",
    "                not_enough_label.add(k)\n",
    "                #print(COVAREP[k]['intervals'][0][0], label[k]['intervals'][0][0])\n",
    "                #print(acoustic, annotations)\n",
    "                #print(k)\n",
    "                #print('acoustic:', COVAREP[k]['intervals'][-1][-1], 'label', label[k]['intervals'][-1][-1])\n",
    "            else:\n",
    "                error_video.add(k)\n",
    "                \n",
    "                #with open(long_video_file, 'w+') as f_w:\n",
    "                #    f_w.write(k + '\\n')\n",
    "            \n",
    "    else:\n",
    "        no_labels.add(k)\n",
    "'''\n",
    "print('========================================') \n",
    "print(len(not_enough_label))\n",
    "print(len(not_enough_word))\n",
    "print(len(error_video))\n",
    "\n",
    "print(len((not_enough_label & not_enough_word)))\n",
    "\n",
    "print(len(no_labels))  \n",
    "print(len(no_labels & set(all_num)))\n",
    "print(len((label_keys - not_enough_label) & not_enough_word))\n",
    "'''   \n",
    "\n",
    "for i, video in enumerate(not_enough_label):\n",
    "    if i < 2:\n",
    "        print(video)\n",
    "        print('COVAREP last interval', COVAREP[video]['intervals'][-1][1])\n",
    "        print('WordVec last interval', WordVec[video]['intervals'][-1][1])\n",
    "        print(label[video]['intervals'][-1][1])\n",
    "        print(label[video]['intervals'][:, :])\n",
    "        #annotations = label[video]['intervals'][-1][1] - label[k]['intervals'][0][0]\n",
    "        #acoustic = COVAREP[video]['intervals'][-1][1]\n",
    "        #print(acoustic / annotations)\n",
    "\n",
    "        \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "video = 'c7xUcM68IFE'\n",
    "print(video in list(COVAREP.keys()))\n",
    "print(video in label_keys)\n",
    "annotations = label[k]['intervals'][-1][1] - label[k]['intervals'][0][0]\n",
    "acoustic = COVAREP[k]['intervals'][-1][1]\n",
    "print(annotations / acoustic > 2)\n",
    "print(acoustic / annotations > 2)\n",
    "print(annotations / acoustic > 2 or acoustic / annotations > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47755102  4.10430839]\n",
      " [ 3.37369615  9.02312925]\n",
      " [ 8.02312925 14.72018141]\n",
      " [44.11111111 54.769161  ]]\n",
      "570.0 0.0\n",
      "569.92 0.0\n"
     ]
    }
   ],
   "source": [
    "video = '-NFrJFQijFE'\n",
    "print(label[video]['intervals'][:10])\n",
    "print(COVAREP[video]['intervals'][-1][1], COVAREP[video]['intervals'][0][0])\n",
    "print(OpenFace[video]['intervals'][-1][1], OpenFace[video]['intervals'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2021-01-24 02:53:58.267] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[93m\u001b[1m[2021-01-24 02:53:58.277] | Warning | \u001b[0mPEBwwe0PLZ8 entry is not shared among all sequences, removing it ...\n",
      "\u001b[92m\u001b[1m[2021-01-24 02:53:58.280] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2021-01-24 02:53:58.280] | Status  | \u001b[0mPre-alignment based on <COVAREP> computational sequence started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3836 [00:00<?, ? Computational Sequence Entries/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Progress:   0%|          | 0/3836 [00:00<?, ? Computational Sequence Entries/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5459 [00:00<?, ? Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:   0%|          | 0/5459 [00:00<?, ? Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2021-01-24 02:54:19.297] | Status  | \u001b[0mPre-alignment done for <WordVec> ...\n",
      "\u001b[94m\u001b[1m[2021-01-24 02:54:20.331] | Status  | \u001b[0mAlignment starting ...\n",
      "(5459, 2)\n",
      "(5459, 74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:   9%|▉         | 513/5459 [00:00<00:00, 5128.32 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  22%|██▏       | 1212/5459 [00:00<00:00, 5572.12 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  35%|███▌      | 1926/5459 [00:00<00:00, 5965.00 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  48%|████▊     | 2647/5459 [00:00<00:00, 6289.07 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  62%|██████▏   | 3361/5459 [00:00<00:00, 6520.21 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  75%|███████▍  | 4084/5459 [00:00<00:00, 6717.07 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aligning: reference: COVAREP, other feature WordVec, video id: HUOMbK1x7MI:  88%|████████▊ | 4807/5459 [00:00<00:00, 6861.71 Segments/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVAREP\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(74,)\n",
      "alignment saved for video 001815.\n",
      "WordVec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Progress:   0%|          | 1/3836 [00:06<6:51:32,  6.44s/ Computational Sequence Entries]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment saved for video 001815.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "video_id_record = os.path.join('/data/mifs_scratch/yw454/cmumosei_aligned', 'video_id.json')\n",
    "\n",
    "with open(video_id_record, 'r') as json_file:\n",
    "    video_ids = json.load(json_file)\n",
    "\n",
    "basic_dataset.align_upsampling_and_save('COVAREP', video_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5459, 74)\n"
     ]
    }
   ],
   "source": [
    "print(COVAREP['HUOMbK1x7MI']['features'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
