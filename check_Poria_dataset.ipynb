{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "2250\n",
      "(2250, 98, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('C:\\\\Users\\\\wangyi66\\\\Desktop\\\\AVS\\\\video_3way.pickle', 'rb') as openfile:\n",
    "    try:\n",
    "        objects = pickle._Unpickler(openfile)\n",
    "        objects.encoding = 'latin1'\n",
    "        A = objects.load()\n",
    "        print(len(A))\n",
    "        print(len(A[0]))\n",
    "        print(A[1].shape)\n",
    "    except EOFError:\n",
    "        print('failed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL above is inrelevant code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\wangyi66\\\\Desktop\\\\cam\\\\Year_four\\\\CMU-MultimodalSDK-Tutorials')\n",
    "from constants import SDK_PATH, DATA_PATH, WORD_EMB_PATH, CACHE_PATH\n",
    "\n",
    "if SDK_PATH is None:\n",
    "    print(\"SDK path is not specified! Please specify first in constants/paths.py\")\n",
    "    exit(0)\n",
    "else:\n",
    "    sys.path.append(SDK_PATH)\n",
    "\n",
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "# create folders for storing the data\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    check_call(' '.join(['mkdir', '-p', DATA_PATH]), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_PATH = 'D:\\\\CMU-MOSEI_Poria\\\\MOSEI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text (2250, 98, 300)\n",
      "valid_text (300, 98, 300)\n",
      "test_text (678, 98, 300)\n",
      "senti_train_label (2250, 98, 1)\n",
      "[ 6  3 10 ...  5 13  1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "audio_path = os.path.join(D_PATH, 'audio.npz')\n",
    "audio = np.load(audio_path, mmap_mode='r')\n",
    "text_path = os.path.join(D_PATH, 'text.npz')\n",
    "text = np.load(text_path, mmap_mode='r')\n",
    "video_path = os.path.join(D_PATH, 'video.npz')\n",
    "video = np.load(video_path, mmap_mode='r')\n",
    "\n",
    "train_text    = text['train_data']\n",
    "train_audio   = audio['train_data']\n",
    "train_video   = video['train_data']\n",
    "print('train_text', train_text.shape)\n",
    "\n",
    "valid_text    = text['valid_data']\n",
    "valid_audio   = audio['valid_data']\n",
    "valid_video   = video['valid_data']\n",
    "print('valid_text', valid_text.shape)\n",
    "\n",
    "test_text     = text['test_data']\n",
    "test_audio    = audio['test_data']\n",
    "test_video    = video['test_data']\n",
    "print('test_text', test_text.shape)\n",
    "\n",
    "senti_train_label   = video['trainSentiLabel']\n",
    "senti_valid_label   = video['validSentiLabel']\n",
    "senti_test_label    = video['testSentiLabel']\n",
    "print('senti_train_label', senti_train_label.shape)\n",
    "\n",
    "#senti_train_label   = to_categorical(senti_train_label >= 0)\n",
    "#senti_valid_label   = to_categorical(senti_valid_label >= 0)\n",
    "#senti_test_label    = to_categorical(senti_test_label >= 0)\n",
    "\n",
    "emo_train_label   = video['trainEmoLabel']\n",
    "emo_valid_label   = video['validEmoLabel']\n",
    "emo_test_label    = video['testEmoLabel']\n",
    "\n",
    "train_length  = video['train_length']\n",
    "valid_length  = video['valid_length']\n",
    "test_length   = video['test_length']\n",
    "print(train_length)\n",
    "\n",
    "#max_segment_len = train_text.shape[1]\n",
    "#print(max_segment_len)\n",
    "#for i in range(2250 // 25):\n",
    "#    print(train_length[i*25:(i+1) * 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 3227\n",
      "train 2249\n",
      "valid 300\n",
      "test 678\n"
     ]
    }
   ],
   "source": [
    "DATASET = md.cmu_mosei\n",
    "all_num = DATASET.standard_folds.standard_train_fold + \\\n",
    "     DATASET.standard_folds.standard_test_fold + \\\n",
    "     DATASET.standard_folds.standard_valid_fold\n",
    "print('all', len(all_num))\n",
    "print('train', len(DATASET.standard_folds.standard_train_fold))\n",
    "print('valid', len(DATASET.standard_folds.standard_valid_fold))\n",
    "print('test', len(DATASET.standard_folds.standard_test_fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmsdk.mmdatasdk import log, computational_sequence\n",
    "import numpy\n",
    "import time\n",
    "import struct\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your different modalities - refer to the filenames of the CSD files\n",
    "basic_dict={'COVAREP': os.path.join(DATA_PATH, 'CMU_MOSEI_COVAREP.csd'), \n",
    "            'WordVec': os.path.join(DATA_PATH, 'CMU_MOSEI_TimestampedWordVectors.csd')}\n",
    "second_dict = {'Facet': os.path.join(DATA_PATH, 'CMU_MOSEI_VisualFacet42.csd'),\n",
    "            'OpenFace': os.path.join(DATA_PATH, 'CMU_MOSEI_VisualOpenFace2.csd')}\n",
    "other_dict = {'Word': os.path.join(DATA_PATH, 'CMU_MOSEI_TimestampedWords.csd'),\n",
    "             'Phone': os.path.join(DATA_PATH, 'CMU_MOSEI_TimestampedPhones.csd')}\n",
    "label_dict = {'mylabels':os.path.join(DATA_PATH, 'CMU_MOSEI_Labels.csd')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2021-02-26 16:59:02.825] | Success | \u001b[0mComputational sequence read from file D:\\cmumosei\\CMU_MOSEI_COVAREP.csd ...\n",
      "\u001b[93m\u001b[1m[2021-02-26 16:59:30.024] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-02-26 16:59:30.040] | Success | \u001b[0mComputational sequence read from file D:\\cmumosei\\CMU_MOSEI_TimestampedWordVectors.csd ...\n",
      "\u001b[93m\u001b[1m[2021-02-26 17:00:03.358] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-02-26 17:00:03.358] | Success | \u001b[0mDataset initialized successfully ... \n",
      "\u001b[92m\u001b[1m[2021-02-26 17:00:03.373] | Success | \u001b[0mComputational sequence read from file D:\\cmumosei\\CMU_MOSEI_VisualFacet42.csd ...\n",
      "\u001b[93m\u001b[1m[2021-02-26 17:00:43.048] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-02-26 17:00:43.048] | Success | \u001b[0mComputational sequence read from file D:\\cmumosei\\CMU_MOSEI_VisualOpenFace2.csd ...\n",
      "\u001b[93m\u001b[1m[2021-02-26 17:01:13.225] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-02-26 17:01:13.225] | Success | \u001b[0mDataset initialized successfully ... \n",
      "\u001b[92m\u001b[1m[2021-02-26 17:01:13.240] | Success | \u001b[0mComputational sequence read from file D:\\cmumosei\\CMU_MOSEI_Labels.csd ...\n",
      "\u001b[93m\u001b[1m[2021-02-26 17:01:14.891] | Warning | \u001b[0mValidation of the computational sequence skipped by user request.\n",
      "\u001b[92m\u001b[1m[2021-02-26 17:01:14.892] | Success | \u001b[0mDataset initialized successfully ... \n"
     ]
    }
   ],
   "source": [
    "basic_dataset = md.mmdataset(basic_dict)\n",
    "second_dataset = md.mmdataset(second_dict)\n",
    "label_dataset = md.mmdataset(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "[COVAREP, WordVec] = [basic_dataset.computational_sequences['COVAREP'],\n",
    "                        basic_dataset.computational_sequences['WordVec']]\n",
    "label = label_dataset.computational_sequences['mylabels']\n",
    "OpenFace = second_dataset.computational_sequences['OpenFace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6666667 0.6666667 0.        0.        0.        0.6666667] [0.         0.         0.33333333 0.66666667 0.66666667 0.        ]\n"
     ]
    }
   ],
   "source": [
    "real_length = []\n",
    "list_label = list(label.keys())\n",
    "pointer = 0\n",
    "for l_l in list_label:\n",
    "    if l_l in DATASET.standard_folds.standard_train_fold:\n",
    "        real_label = label[l_l]['features'][0,1:]\n",
    "        poria_label = emo_train_label[pointer][0]\n",
    "        senti_train_label\n",
    "        #if real_label == poria_label:\n",
    "        #    print(True)\n",
    "        print(real_label, poria_label)\n",
    "    \n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
